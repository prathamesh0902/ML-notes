{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2a8c926-616d-432b-9c87-5e2b09f3a2d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "qepWRFxSvl_s"
   },
   "source": [
    "# Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f53b5114-f6d6-4cf8-b005-00e4517a77bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "b5UWCqoOvl_x"
   },
   "outputs": [],
   "source": [
    "# %pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a9bcd33-2160-4035-ba47-1473da9cb30f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "JAzBp0mavl_1"
   },
   "source": [
    "<font color = 'yellow'> %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59444d36-088d-4e2b-a4d8-76fe3be4995f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "5YWv9RiYvl_3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1f91735-33d2-4b19-82e2-964860ccdf14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "3i2tiq3Qvl_5",
    "outputId": "248ac21d-9043-4525-baa3-e3d01b4be93c"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# create a data frame with 3 rows and 4 columns\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9], 'D': [10, 11, 12]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd59ba96-dac4-469b-ab75-bb5adc88213f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "pton2mj-vl__"
   },
   "source": [
    "<font color = 'yellow'> %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "083f0a55-614c-4c52-a911-258f41e04596",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "cKtkiqwuvmAC"
   },
   "source": [
    "### Data Manipulation Commands\n",
    "\n",
    "0. **Creating DataFrame**:\n",
    "   ```python\n",
    "   df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9], 'D': [10, 11, 12]})\n",
    "   ```\n",
    "\n",
    "1. **Selecting Columns**:\n",
    "   ```python\n",
    "   df['column_name']\n",
    "   ```\n",
    "\n",
    "2. **Selecting Multiple Columns**:\n",
    "   ```python\n",
    "   df[['column1', 'column2']]\n",
    "   ```\n",
    "\n",
    "3. **Filtering Rows**:\n",
    "   ```python\n",
    "   df[df['column_name'] > value]\n",
    "   ```\n",
    "\n",
    "4. **Creating New Columns**:\n",
    "   ```python\n",
    "   df['new_column'] = df['column1'] + df['column2']\n",
    "   ```\n",
    "\n",
    "5. **Dropping Columns**:\n",
    "   ```python\n",
    "   df.drop('column_name', axis=1, inplace=True)\n",
    "   ```\n",
    "\n",
    "6. **Renaming Columns**:\n",
    "   ```python\n",
    "   df.rename(columns={'old_name': 'new_name'}, inplace=True)\n",
    "   ```\n",
    "\n",
    "7. **Sorting Values**:\n",
    "   ```python\n",
    "   df.sort_values(by='column_name', ascending=True)\n",
    "   ```\n",
    "\n",
    "8. **Resetting Index**:\n",
    "   ```python\n",
    "   df.reset_index(drop=True, inplace=True)\n",
    "   ```\n",
    "\n",
    "9. **Null Values**:\n",
    "   ```python\n",
    "   null_values = df.isnull().sum()\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0db2b15-a79c-4bf3-8c34-4a5f2fdc04cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Rkx8kdbVvmAF"
   },
   "source": [
    "<font color = 'yellow'> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ </font>\n",
    "\n",
    "### Grouping Commands\n",
    "\n",
    "1. **Group By Single Column**:\n",
    "   ```python\n",
    "   df.groupby('column_name')\n",
    "   ```\n",
    "\n",
    "2. **Group By Multiple Columns**:\n",
    "   ```python\n",
    "   df.groupby(['column1', 'column2'])\n",
    "   ```\n",
    "\n",
    "3. **Aggregating Data After Grouping**:\n",
    "   ```python\n",
    "   df.groupby('column_name').agg({'column_to_aggregate': 'sum'})\n",
    "   ```\n",
    "\n",
    "4. **Applying Multiple Aggregations**:\n",
    "   ```python\n",
    "   df.groupby('column_name').agg({'column1': 'sum', 'column2': 'mean'})\n",
    "   ```\n",
    "\n",
    "5. **Getting Group Size**:\n",
    "   ```python\n",
    "   df.groupby('column_name').size()\n",
    "   ```\n",
    "\n",
    "6. **Applying Custom Functions**:\n",
    "   ```python\n",
    "   df.groupby('column_name').apply(lambda x: x['column_to_apply_function'] * 2)\n",
    "   ```\n",
    "\n",
    "These commands cover a wide range of basic data manipulation and grouping tasks you can perform on pandas DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9f72120-3544-463b-87af-6fab73aba263",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "MN-8RwcIvmAI"
   },
   "source": [
    "<font color = 'yellow'> %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "730fb5a3-2fbb-4c75-b8a7-51ffbe1cb8a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Nb77q3BUvmAL"
   },
   "source": [
    "Here are some basic operations for identifying and filling in null values in a DataFrame using `pandas`:\n",
    "\n",
    "### Identifying Null Values\n",
    "\n",
    "1. **Check for any null values in the DataFrame:**\n",
    "   ```python\n",
    "   df.isnull().any().any()\n",
    "   ```\n",
    "\n",
    "2. **Count the number of null values in each column:**\n",
    "   ```python\n",
    "   null_counts = df.isnull().sum()\n",
    "   print(null_counts)\n",
    "   ```\n",
    "\n",
    "3. **Display rows with any null values:**\n",
    "   ```python\n",
    "   rows_with_nulls = df[df.isnull().any(axis=1)]\n",
    "   print(rows_with_nulls)\n",
    "   ```\n",
    "\n",
    "### Filling Null Values\n",
    "\n",
    "1. **Fill null values with a specific value (e.g., 0):**\n",
    "   ```python\n",
    "   df_filled = df.fillna(0)\n",
    "   ```\n",
    "\n",
    "2. **Fill null values with the mean of the column:**\n",
    "   ```python\n",
    "   df['column_name'] = df['column_name'].fillna(df['column_name'].mean())\n",
    "   ```\n",
    "\n",
    "3. **Fill null values with the median of the column:**\n",
    "   ```python\n",
    "   df['column_name'] = df['column_name'].fillna(df['column_name'].median())\n",
    "   ```\n",
    "\n",
    "4. **Fill null values with the mode of the column:**\n",
    "   ```python\n",
    "   df['column_name'] = df['column_name'].fillna(df['column_name'].mode()[0])\n",
    "   ```\n",
    "\n",
    "5. **Forward fill (propagate last valid observation forward to next valid):**\n",
    "   ```python\n",
    "   df_filled = df.fillna(method='ffill')\n",
    "   ```\n",
    "\n",
    "6. **Backward fill (use next valid observation to fill gap):**\n",
    "   ```python\n",
    "   df_filled = df.fillna(method='bfill')\n",
    "   ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0378e3c0-1c39-4b85-8521-16572acd4a68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "PHbcAwqZvmAM"
   },
   "source": [
    "\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "pd.DataFrame({'Bob': ['I liked it.', 'It was awful.'], 'Sue': ['Pretty good.', 'Bland.']}, index=['Product A', 'Product B'])\n",
    "pd.Series([30, 35, 40], index=['2015 Sales', '2016 Sales', '2017 Sales'], name='Product A')\n",
    "wine_reviews = pd.read_csv(\"../input/wine-reviews/winemag-data-130k-v2.csv\", index_col=0)\n",
    ".shape\t\t.head()\n",
    "reviews.iloc[[0, 1, 2], 0]\t\t\treviews.loc[[0,1,10,100], ['country','province','region_1','region_2']]\n",
    "reviews.set_index(\"title\")\t\t\tsample_reviews = reviews.loc[[1,2,3,5,8], :]\n",
    "reviews.loc[((reviews.country == 'Australia') | (reviews.country == 'New Zealand')) & (reviews.points >= 95) ]\n",
    "reviews.loc[reviews.country.isin(['Italy', 'France'])]          reviews.loc[reviews.price.notnull()]\n",
    "first_descriptions = reviews.description.iloc[0:10]\n",
    "reviews.taster_name.describe()\t\t\tunique()\t\t\tvalue_counts()\n",
    "reviews.points.mean()                   reviews['critic'] = 'everyone'\n",
    "\n",
    "MAPS\n",
    "reviews.points.map(lambda p: p - review_points_mean)\n",
    "n_fruity = reviews.description.map(lambda desc: \"fruity\" in desc).sum()\n",
    "reviews.country + \" - \" + reviews.region_1\n",
    "\n",
    "def remean_points(row):\n",
    "    row.points = row.points - review_points_mean\n",
    "    return row\n",
    "\n",
    "reviews.apply(remean_points, axis='columns')\n",
    "\n",
    "reviews.groupby('variety').price.agg([min,max])\n",
    "#reviews.groupby(['variety']).apply(lambda df: df.loc[df.price.notnull().idxmax()]).sort_values(by='price',ascending=False )\n",
    "reviews.groupby('variety').price.max().sort_values(ascending=False )\n",
    "reviews.groupby(['country', 'variety']).size().sort_values(ascending=False)\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f3b2f0b-a51b-4ec5-870c-490335d0ae4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "vEkNZX5-vmAN"
   },
   "source": [
    "Numpy Tutorial - https://cs231n.github.io/python-numpy-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c79e05a9-854c-48e3-a195-a15cb745663d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "9eJQzCTwvmAP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute the x and y coordinates for points on sine and cosine curves\n",
    "x = np.arange(0, 3 * np.pi, 0.1)\n",
    "y_sin = np.sin(x)\n",
    "y_cos = np.cos(x)\n",
    "\n",
    "# Set up a subplot grid that has height 2 and width 1,\n",
    "# and set the first such subplot as active.\n",
    "plt.subplot(2, 1, 1)\n",
    "\n",
    "# Make the first plot\n",
    "plt.plot(x, y_sin)\n",
    "plt.title('Sine')\n",
    "\n",
    "# Set the second subplot as active, and make the second plot.\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(x, y_cos)\n",
    "plt.title('Cosine')\n",
    "\n",
    "# Show the figure.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ae1da30-7289-48a9-b652-5162582121da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "nrr5h4hNvmAU"
   },
   "source": [
    "# LSTM model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2406e731-e006-42c3-b9de-f2c8ec4426b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "vZiKKCrfvmAV"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# Define the LSTM model function\n",
    "def create_model(learn_rate=0.001, neurons=50):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, input_shape=(window_size, 1)))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=learn_rate)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "# Create a KerasRegressor object\n",
    "model = KerasRegressor(build_fn=create_model, epochs=10, batch_size=1, verbose=1)\n",
    "\n",
    "# Define hyperparameters for grid search\n",
    "param_grid = {\n",
    "    'learn_rate': [0.001, 0.01, 0.1],\n",
    "    'neurons': [50, 100, 150]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f72304aa-cd29-47df-ab08-d51d27566c97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "qzhN1YDdvmAt"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d25c55d-3af9-4466-8bcc-2205d9bcefb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tlR4wXQQvmAu"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.style.use(\"dark_background\")\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# reviews_sample.columns.str.strip().str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f2a1cf5-5bc9-4bde-9a07-4b78c3f78773",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "rGAz5IyXvmAv"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31470cff-2956-497e-b658-9c58c26251aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1Zqyuyo6vmAX"
   },
   "source": [
    "## Export to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0dd40ba-a474-497a-9812-3dd8c6688454",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "D1x44duxvmAY"
   },
   "outputs": [],
   "source": [
    "pip install nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "188d5479-a03c-4e07-9224-84c18aae91d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "szLko-NGvmAY"
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html Hw_3.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab06ffef-d6bd-4788-8398-22dfe05fe482",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d9c339c-510f-4f1c-a58a-c1e149b30710",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrames\n",
    "data1 = {'OuterIndex': ['A', 'A', 'B', 'B', 'C'],\n",
    "         'Value1': [10, 20, 30, 40, 50]}\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "data2 = {'OuterIndex': ['A', 'B', 'C'],\n",
    "         'Value2': [100, 200, 300]}\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Set the 'OuterIndex' column as the index for both DataFrames\n",
    "df1.set_index('OuterIndex', inplace=True)\n",
    "df2.set_index('OuterIndex', inplace=True)\n",
    "\n",
    "# Select rows from df1 based on the outer index from df2\n",
    "selected_rows = df1.loc[df2.index]\n",
    "\n",
    "print(selected_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cac988e-a3e2-4b5b-85c1-ac720ad9758f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    ('California', 'Apple'): [100, 150],\n",
    "    ('California', 'Banana'): [200, 250],\n",
    "    ('New York', 'Apple'): [50, 75],\n",
    "    ('New York', 'Banana'): [100, 120],\n",
    "}\n",
    "\n",
    "# Create a multi-index\n",
    "index = pd.MultiIndex.from_tuples(data.keys(), names=['State', 'Fruit'])\n",
    "\n",
    "# Create the DataFrame\n",
    "multi_index_df = pd.DataFrame(data.values(), index=index, columns=['Quantity_2019', 'Quantity_2020'])\n",
    "\n",
    "# Display the multi-indexed DataFrame\n",
    "print(multi_index_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7130353c-0e6d-44d4-960f-e827e3d3dcc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "### What is Creating Data Dictionaries for a Database?\n",
    "\n",
    "Creating a **data dictionary** for a database involves compiling a detailed, organized set of descriptions and definitions for all the data elements (fields) within a database. It serves as a reference guide for understanding the structure, relationships, and rules governing the data within the database.\n",
    "\n",
    "### Key Components of a Data Dictionary\n",
    "\n",
    "1. **Table Descriptions**:\n",
    "   - **Table Name**: The name of the table.\n",
    "   - **Description**: A brief explanation of what data the table contains.\n",
    "\n",
    "2. **Field (Column) Descriptions**:\n",
    "   - **Field Name**: The name of the field (column).\n",
    "   - **Data Type**: The type of data stored in the field (e.g., INTEGER, VARCHAR, DATE).\n",
    "   - **Description**: A detailed explanation of what the field represents.\n",
    "   - **Constraints**: Any rules or restrictions on the data (e.g., NOT NULL, UNIQUE).\n",
    "   - **Default Value**: The default value for the field, if any.\n",
    "   - **Primary Key**: Whether the field is a primary key.\n",
    "   - **Foreign Key**: References to other tables or fields, if the field is a foreign key.\n",
    "   - **Allowed Values**: A list of permissible values for fields with limited options (e.g., ENUM types).\n",
    "   - **Index Information**: Details on indexing for performance optimization.\n",
    "\n",
    "3. **Relationship Descriptions**:\n",
    "   - **Relationships Between Tables**: Documentation of how tables are related to each other (e.g., one-to-many, many-to-many relationships).\n",
    "   - **Foreign Key Relationships**: Which fields in a table link to fields in other tables.\n",
    "\n",
    "4. **Business Rules**:\n",
    "   - **Validation Rules**: Specific rules that data must adhere to (e.g., age must be > 18).\n",
    "   - **Calculation Rules**: Any calculations or derived fields based on other data in the database.\n",
    "\n",
    "5. **Data Usage**:\n",
    "   - **Ownership**: Who is responsible for the data within each table or field.\n",
    "   - **Security and Access Controls**: Who has access to read, write, or modify the data.\n",
    "   - **Data Retention**: Rules on how long data is stored and when it can be deleted or archived.\n",
    "\n",
    "### Importance of a Data Dictionary\n",
    "\n",
    "1. **Consistency and Clarity**: Ensures everyone understands the data structure, reducing errors and misinterpretation.\n",
    "2. **Documentation**: Acts as comprehensive documentation for developers, analysts, and administrators.\n",
    "3. **Data Integrity**: Helps maintain the integrity of the database by clearly defining rules and constraints.\n",
    "4. **Onboarding**: Assists new team members in quickly understanding the database structure and its data.\n",
    "5. **Compliance**: Supports adherence to legal and regulatory standards by clearly documenting data storage and usage practices.\n",
    "\n",
    "### Example of a Data Dictionary Entry\n",
    "\n",
    "Hereâ€™s an example of what a data dictionary entry might look like for a simple database table called `Customer`:\n",
    "\n",
    "| **Field Name** | **Data Type** | **Description**                       | **Constraints** | **Default Value** | **Primary Key** | **Foreign Key** | **Allowed Values** |\n",
    "|----------------|---------------|---------------------------------------|-----------------|------------------|----------------|-----------------|--------------------|\n",
    "| `CustomerID`   | INTEGER       | Unique identifier for each customer   | NOT NULL        | Auto-increment   | Yes            | None            | N/A                |\n",
    "| `FirstName`    | VARCHAR(50)   | The customer's first name             | NOT NULL        | None             | No             | None            | N/A                |\n",
    "| `LastName`     | VARCHAR(50)   | The customer's last name              | NOT NULL        | None             | No             | None            | N/A                |\n",
    "| `Email`        | VARCHAR(100)  | The customer's email address          | UNIQUE, NOT NULL| None             | No             | None            | N/A                |\n",
    "| `DateOfBirth`  | DATE          | The customer's date of birth          | NOT NULL        | None             | No             | None            | N/A                |\n",
    "| `AccountType`  | ENUM('Free', 'Premium') | The type of account the customer holds | NOT NULL | 'Free' | No | None | 'Free', 'Premium' |\n",
    "\n",
    "### How to Create a Data Dictionary\n",
    "\n",
    "1. **Identify Database Elements**: List all tables, fields, and relationships in the database.\n",
    "2. **Gather Descriptions**: Document what each table, field, and relationship represents.\n",
    "3. **Define Data Types**: Clearly define the data types and constraints for each field.\n",
    "4. **Review Business Rules**: Include any business rules, validation requirements, and calculations.\n",
    "5. **Document Relationships**: Explain how tables relate to each other (e.g., foreign keys).\n",
    "6. **Ensure Completeness**: Review and update the data dictionary regularly to reflect any changes in the database schema.\n",
    "\n",
    "Creating a data dictionary is a critical step in database design and management, ensuring that everyone who interacts with the database understands its structure, rules, and purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90bf26c4-5d54-43d0-bae9-a3de58fbdad9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5_Pandas_DataFrame",
   "widgets": {}
  },
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
